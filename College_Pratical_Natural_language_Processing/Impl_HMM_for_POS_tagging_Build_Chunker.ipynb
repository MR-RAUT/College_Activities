{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Implement HMM for POS tagging. Build a Chunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "import nltk\n",
    "from nltk.tag import hmm\n",
    "from nltk.corpus import treebank\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Jaydip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Jaydip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\Jaydip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n",
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\Jaydip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download necessary resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('universal_tagset')\n",
    "nltk.download('treebank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tagged sentences from the Penn Treebank corpus\n",
    "tagged_sentences = treebank.tagged_sents(tagset='universal')  # Using Universal POS tagset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "train_data = tagged_sentences[:3000]  # First 3000 sentences for training\n",
    "test_data = tagged_sentences[3000:]  # Remaining for testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data is :  [[('At', 'ADP'), ('Tokyo', 'NOUN'), (',', '.'), ('the', 'DET'), ('Nikkei', 'NOUN'), ('index', 'NOUN'), ('of', 'ADP'), ('225', 'NUM'), ('selected', 'VERB'), ('issues', 'NOUN'), (',', '.'), ('which', 'DET'), ('*T*-1', 'X'), ('gained', 'VERB'), ('132', 'NUM'), ('points', 'NOUN'), ('Tuesday', 'NOUN'), (',', '.'), ('added', 'VERB'), ('14.99', 'NUM'), ('points', 'NOUN'), ('to', 'PRT'), ('35564.43', 'NUM'), ('.', '.')], [('In', 'ADP'), ('early', 'ADV'), ('trading', 'NOUN'), ('in', 'ADP'), ('Tokyo', 'NOUN'), ('Thursday', 'NOUN'), (',', '.'), ('the', 'DET'), ('Nikkei', 'NOUN'), ('index', 'NOUN'), ('fell', 'VERB'), ('63.79', 'NUM'), ('points', 'NOUN'), ('to', 'PRT'), ('35500.64', 'NUM'), ('.', '.')], ...]\n",
      "train data is :  [[('Pierre', 'NOUN'), ('Vinken', 'NOUN'), (',', '.'), ('61', 'NUM'), ('years', 'NOUN'), ('old', 'ADJ'), (',', '.'), ('will', 'VERB'), ('join', 'VERB'), ('the', 'DET'), ('board', 'NOUN'), ('as', 'ADP'), ('a', 'DET'), ('nonexecutive', 'ADJ'), ('director', 'NOUN'), ('Nov.', 'NOUN'), ('29', 'NUM'), ('.', '.')], [('Mr.', 'NOUN'), ('Vinken', 'NOUN'), ('is', 'VERB'), ('chairman', 'NOUN'), ('of', 'ADP'), ('Elsevier', 'NOUN'), ('N.V.', 'NOUN'), (',', '.'), ('the', 'DET'), ('Dutch', 'NOUN'), ('publishing', 'VERB'), ('group', 'NOUN'), ('.', '.')], ...]\n"
     ]
    }
   ],
   "source": [
    "print(\"test data is : \",test_data)\n",
    "print(\"train data is : \",train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train an HMM POS tagger\n",
    "trainer = hmm.HiddenMarkovModelTrainer()\n",
    "hmm_tagger = trainer.train(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Sentence: ['At', 'Tokyo', ',', 'the', 'Nikkei', 'index', 'of', '225', 'selected', 'issues', ',', 'which', '*T*-1', 'gained', '132', 'points', 'Tuesday', ',', 'added', '14.99', 'points', 'to', '35564.43', '.']\n"
     ]
    }
   ],
   "source": [
    "# Test the tagger on the test data\n",
    "test_sentence = [word for word, _ in test_data[0]]  # Extract words from the first test sentence\n",
    "print(\"Test Sentence:\", test_sentence)\n",
    "predicted_tags = hmm_tagger.tag(test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HMM POS Tagging:\n",
      "At: ADP\n",
      "Tokyo: NOUN\n",
      ",: .\n",
      "the: DET\n",
      "Nikkei: NOUN\n",
      "index: NOUN\n",
      "of: NOUN\n",
      "225: NOUN\n",
      "selected: NOUN\n",
      "issues: NOUN\n",
      ",: NOUN\n",
      "which: NOUN\n",
      "*T*-1: NOUN\n",
      "gained: NOUN\n",
      "132: NOUN\n",
      "points: NOUN\n",
      "Tuesday: NOUN\n",
      ",: NOUN\n",
      "added: NOUN\n",
      "14.99: NOUN\n",
      "points: NOUN\n",
      "to: NOUN\n",
      "35564.43: NOUN\n",
      ".: NOUN\n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "print(\"\\nHMM POS Tagging:\")\n",
    "for word, tag in predicted_tags:\n",
    "    print(f\"{word}: {tag}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
